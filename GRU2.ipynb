{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "RNN2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mk-a/NLP_Duty1/blob/master/GRU2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wSjIcQNZxob5",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from collections import Counter\n",
        "import pickle\n",
        "import torch.nn as nn\n",
        "import time\n",
        "import gc\n",
        "import copy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4vQ31UX4xw5p",
        "outputId": "b3bc9950-18b0-4377-c629-85f97c1bbaba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3JRJmFEHxyIM",
        "outputId": "d3d59bd7-4485-4340-d219-70ab5a71bc4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tKM52fQMx0HB",
        "colab": {}
      },
      "source": [
        "train_df = pd.read_pickle(\"/content/drive/My Drive/Colab Notebooks/IFT6285/train_post_preprocessed2.pkl\")\n",
        "valid_df = pd.read_pickle(\"/content/drive/My Drive/Colab Notebooks/IFT6285/test_preprocessed.pkl\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMVow-GSZjua",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0b292911-e01e-4270-97e2-43fe333a150f"
      },
      "source": [
        "(np.array([len(a) for a in train_df.text.values]) < 300).sum()/len(train_df)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7631698557826421"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apFLw4DZxu7Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "count_words = Counter()\n",
        "for post in train_df.text.values:\n",
        "    for tok in post:\n",
        "        count_words[tok] += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kwx4k4dgx1Qx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "59e6b9bf-8ed4-4fd6-d9d8-123f1b2ec88d"
      },
      "source": [
        "len(count_words)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "685119"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfBrRogTyFQy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "773db7fd-83e0-418f-e2cb-089bce22d747"
      },
      "source": [
        "len([w for w in count_words if count_words[w]==1])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "408247"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVe540zNyQ5h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "da15cd87-10ff-4435-a276-f10214d4df8a"
      },
      "source": [
        "len(count_words) - len([w for w in count_words if count_words[w]==1])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "276872"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6Z8iZzCOpOd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "14ecd51e-9e15-4588-801d-96ff160be356"
      },
      "source": [
        "len(train_df)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "512629"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4izxu0lRyB-u",
        "colab": {}
      },
      "source": [
        "def text2seq(X, y, seq_len, vocab_max=None, word2idx=None ):\n",
        "    \"\"\" For a list of inputs X with different sequence length, associated to the labels y.\n",
        "        Builds the list of the vocab_max-2 most common words. Maps each of them to a number.\n",
        "        Replace the other words by the token unk_tok, which is mapped to the value 1.\n",
        "        Then force the input to have a sequence length of seq_len with this policy:\n",
        "            - If the sample x is short than seq_len, then adds padding at the begining.\n",
        "            The padding token is set by the variable padd_tok. And mapped to the value 0.\n",
        "            - If the sample x is longer than seq_len, then extracts (len(x)//seq_len)+1\n",
        "            sequences from x.\n",
        "    \"\"\"\n",
        "    if word2idx == None:\n",
        "        count_words = Counter()\n",
        "        for post in X:\n",
        "            for tok in post:\n",
        "                count_words[tok] += 1\n",
        "        if vocab_max == None:\n",
        "            vocab_max = len(count_words) + 2\n",
        "        vocab = {w for w,_ in count_words.most_common(vocab_max-2)}\n",
        "        word2idx = {w : i+2 for i, (w,_) in enumerate( count_words.most_common(vocab_max-2) )}\n",
        "        word2idx[\"PAD\"] = 0\n",
        "        word2idx[\"UNK\"] = 1\n",
        "    else:\n",
        "        vocab = {k for k in word2idx.keys()}\n",
        "\n",
        "    X2 = []\n",
        "    y2 = []\n",
        "    for i, x in enumerate(X):\n",
        "        if len(x) < seq_len:\n",
        "            tmp = x.copy()\n",
        "            for _ in range(seq_len - len(x)):\n",
        "                tmp.insert(0, 'PAD')\n",
        "            X2.append([word2idx[tok] if tok in vocab else 1 for tok in tmp])\n",
        "            y2.append(y[i])\n",
        "        elif len(x) == seq_len:\n",
        "            X2.append([word2idx[tok] if tok in vocab else 1 for tok in x]) \n",
        "            y2.append(y[i])\n",
        "        else :\n",
        "            for j in range(len(x)//seq_len):\n",
        "                X2.append([word2idx[tok] if tok in vocab else 1 for tok in  x[j*seq_len:(j+1)*seq_len]])\n",
        "                y2.append(y[i])\n",
        "            X2.append([word2idx[tok] if tok in vocab else 1 for tok in  x[-seq_len:]])\n",
        "            y2.append(y[i])\n",
        "    return word2idx, X2, y2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9wOd_UWgyEk3",
        "colab": {}
      },
      "source": [
        "vocab_max = 276874\n",
        "word2idx, X_train, y_train = text2seq(train_df.text.values, train_df.label.values, 300, vocab_max) \n",
        "_, X_valid, y_valid = text2seq(valid_df.text.values, valid_df.label.values, 300, word2idx=word2idx) \n",
        "# del data\n",
        "# gc.collect()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMJOJGRYOuZg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c72bd404-752f-41e3-b673-9c572158f69d"
      },
      "source": [
        "len(X_train)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "705845"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HTh-vz6GyJj8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "outputId": "de3faceb-2fb5-416e-8d6c-ff99332ab785"
      },
      "source": [
        "# with open('/content/drive/My Drive/Colab Notebooks/IFT6285/word2idx_{}.pkl'.format(vocab_max), 'wb') as handle:\n",
        "#     pickle.dump(word2idx, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "# with open('/content/drive/My Drive/Colab Notebooks/IFT6285/X_v{}_s300.pkl'.format(vocab_max), 'wb') as handle:\n",
        "#     pickle.dump(X_tra, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "# with open('/content/drive/My Drive/Colab Notebooks/IFT6285/y_s300.pkl', 'wb') as handle:\n",
        "#     pickle.dump(y, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-b0692696d1fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword2idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHIGHEST_PROTOCOL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/Colab Notebooks/IFT6285/X_v{}_s300.pkl'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHIGHEST_PROTOCOL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/Colab Notebooks/IFT6285/y_s300.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHIGHEST_PROTOCOL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wobTeBnoXkay",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load files\n",
        "# with open('/content/drive/My Drive/Colab Notebooks/IFT6285/v2/word2val_284467.pkl', 'rb') as handle:\n",
        "#     word2val = pickle.load(handle)\n",
        "# with open('/content/drive/My Drive/Colab Notebooks/IFT6285/v2/X_v284467_s200.pkl', 'rb') as handle:\n",
        "#     X = pickle.load(handle)\n",
        "# with open('/content/drive/My Drive/Colab Notebooks/IFT6285/v2/y_s200.pkl', 'rb') as handle:\n",
        "#     y = pickle.load(handle)\n",
        "# vocab_max = 284467"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6j1yuP4oyknm",
        "colab": {}
      },
      "source": [
        "# X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.33, random_state=42)\n",
        "# X_train, X_valid, y_train, y_valid = train_test_split(X2, y2, test_size=0.33, random_state=42)\n",
        "# X_valid, X_test, y_valid, y_test = train_test_split(X_valid, y_valid, test_size=0.5, random_state=42)\n",
        "\n",
        "X_train = torch.tensor(X_train)\n",
        "X_valid = torch.tensor(X_valid)\n",
        "# X_test = torch.tensor(X_test)\n",
        "\n",
        "y_train = torch.tensor(y_train)\n",
        "y_valid = torch.tensor(y_valid)\n",
        "# y_test = torch.tensor(y_test)\n",
        "\n",
        "train_data = torch.utils.data.TensorDataset(X_train, y_train)\n",
        "valid_data = torch.utils.data.TensorDataset(X_valid, y_valid)\n",
        "# test_data = torch.utils.data.TensorDataset(X_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IYVFMa62ynr7",
        "colab": {}
      },
      "source": [
        "batch_size = 256\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
        "valid_loader = torch.utils.data.DataLoader(valid_data, shuffle=True, batch_size=batch_size)\n",
        "# test_loader = torch.utils.data.DataLoader(test_data, shuffle=True, batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LM9IdpRuU8Dd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GRU(nn.Module):\n",
        "    def __init__(self,\n",
        "                 emb_size,\n",
        "                 hidden_size,\n",
        "                 vocab_size,\n",
        "                 num_layers,\n",
        "                 output_size,\n",
        "                 nonlinearity = 'relu',\n",
        "                 bias = True,\n",
        "                 dropout = 0,\n",
        "                 bidirectional = True\n",
        "                ):\n",
        "        super(GRU, self).__init__()\n",
        "        #hyper-parameters\n",
        "        self.emb_size      = emb_size\n",
        "        self.hidden_size   = hidden_size\n",
        "        self.vocab_size    = vocab_size\n",
        "        self.num_layers    = num_layers\n",
        "        self.output_size   = output_size\n",
        "        self.nonlinearity  = nonlinearity\n",
        "        self.bias          = bias\n",
        "        self.dropout       = dropout\n",
        "        self.bidirectional = bidirectional\n",
        "        #layers\n",
        "        self.embedding = nn.Embedding(vocab_size, emb_size).to(device)\n",
        "        self.gru = nn.GRU(input_size = emb_size,\n",
        "                          hidden_size = hidden_size,\n",
        "                          num_layers = num_layers,\n",
        "                          bias = bias,\n",
        "                          dropout = dropout,\n",
        "                          bidirectional = bidirectional\n",
        "                         ).to(device)\n",
        "        self.linear = nn.Linear((bidirectional+1) *hidden_size, output_size).to(device)\n",
        "        \n",
        "    def forward(self, X):\n",
        "        out = self.embedding(X.t())\n",
        "        out, _ = self.gru(out)\n",
        "        return self.linear(out[-1])\n",
        "    \n",
        "    def predict(self, data):\n",
        "        if isinstance(data, torch.utils.data.DataLoader):\n",
        "            y = []\n",
        "            for i in range((len(data.dataset)//data.batch_size)+1):\n",
        "                imin = i*data.batch_size\n",
        "                imax = min((i+1)*batch_size, len(data.dataset))\n",
        "                y.append(self.forward(data.dataset[imin:imax][0].to(device)).max(dim=1)[1])\n",
        "            return torch.cat(y)\n",
        "        elif isinstance(data, torch.Tensor):\n",
        "            return self.forward(data.to(device)).max(dim=1)[1]\n",
        "        elif isinstance(data, torch.utils.data.dataset.TensorDataset):\n",
        "            return self.predict(data.tensors[0])\n",
        "        else:\n",
        "            raise AttributeError(\"data must be an instance of DataLoader, Tensor or TensorDataset\")\n",
        "        \n",
        "\n",
        "    def accuracy(self, X, y=None):\n",
        "        if isinstance(X, torch.utils.data.DataLoader):\n",
        "            return (self.predict(X) == X.dataset.tensors[1].to(device)).float().sum().item() / len(X.dataset.tensors[1])\n",
        "        elif isinstance(X, torch.Tensor) and isinstance(y, torch.Tensor):\n",
        "            return (self.predict(X.to(device)) == y.to(device)).float().sum().item() / len(y)\n",
        "        else :\n",
        "            raise AttributeError(\"Must be called with X as a DataLoader or X and y some Tensor\")\n",
        "    \n",
        "    def f1_score(self, data_loader, label=1):\n",
        "        return f1_score((data_loader.dataset[:][1] == label).int().cpu().numpy(),\n",
        "                        (self.predict(data_loader) == label).int().cpu().numpy() )\n",
        "\n",
        "    def run_epoch(self, n_epochs, criterion, optimizer, train_loader,\n",
        "                  valid_loader=None, early_stop=True, patience=1 ):\n",
        "        start_time = time.time()\n",
        "        last_time = time.time()\n",
        "        if valid_loader:\n",
        "            best_score = -1\n",
        "            best_param = None\n",
        "            epochs_since_best_score = 0\n",
        "        for epoch in range(1, n_epochs+1):\n",
        "            print(\"Epoch: {}/{}\".format(epoch, n_epochs))\n",
        "            running_loss = 0\n",
        "            for i, (X_batch, y_batch) in enumerate(train_loader):\n",
        "                y_batch = y_batch.to(device)\n",
        "                torch.cuda.empty_cache()\n",
        "                optimizer.zero_grad()\n",
        "                out = self.forward(X_batch.to(device))\n",
        "                loss = criterion(out, y_batch)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                running_loss += loss.item()\n",
        "            train_score = self.accuracy(train_loader)\n",
        "            if valid_loader:\n",
        "                valid_score = self.accuracy(valid_loader)\n",
        "                print(\"loss: {:.6f}\\ttrain_acc: {:.4f}\\telapsed_time: {:.1f}s\\tvalid_acc: {:.4f}\".format(\n",
        "                    running_loss/len(train_loader.dataset), train_score, time.time()-start_time, valid_score))\n",
        "                if best_score > valid_score:\n",
        "                    epochs_since_best_score +=1\n",
        "                    if early_stop and epochs_since_best_score == patience:\n",
        "                        print(\"Early stopping. Resetting the parameters of the\\\n",
        "                        best score on the validation set.\")\n",
        "                        self.load_state_dict(best_param)\n",
        "                        return\n",
        "                else:\n",
        "                    best_score  = valid_score\n",
        "                    best_param = copy.deepcopy(self.state_dict())\n",
        "                    epochs_since_best_score = 0\n",
        "            else:\n",
        "                print(\"loss: {:.6f}\\ttrain_acc: {:.4f}\\telapsed_time: {:.1f}s\".format(\n",
        "                    running_loss/len(train_loader.dataset), train_score, time.time()-start_time))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zR2Odn1kyvpd",
        "colab": {}
      },
      "source": [
        "model = 'GRU'\n",
        "emb_size = 32\n",
        "hidden_size = 64\n",
        "num_layers = 4\n",
        "output_size = 3\n",
        "bidirectional=False\n",
        "dropout = 0\n",
        "filename = '{}{}_emb{}_hid{}_lay{}_vocab{}_dp{}.pt'.format('bi' if bidirectional else '', model, emb_size, hidden_size, num_layers, vocab_max, dropout )\n",
        "\n",
        "\n",
        "gru = GRU(emb_size = emb_size, hidden_size = hidden_size, vocab_size = vocab_max,\n",
        "          num_layers = num_layers, output_size = output_size, bidirectional=bidirectional, dropout=dropout)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7NzXV3bfy24C",
        "colab": {}
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(gru.parameters(), weight_decay=10e-5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mwj3dCXby5aJ",
        "outputId": "b120561f-b6df-4f31-bc40-7d3f4a970929",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "gru.run_epoch(n_epochs=20, criterion=criterion, optimizer=optimizer, train_loader=train_loader, valid_loader=valid_loader, early_stop=True, patience=5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1/20\n",
            "loss: 0.003319\ttrain_acc: 0.6411\telapsed_time: 264.5s\tvalid_acc: 0.6012\n",
            "Epoch: 2/20\n",
            "loss: 0.002900\ttrain_acc: 0.6872\telapsed_time: 529.7s\tvalid_acc: 0.6309\n",
            "Epoch: 3/20\n",
            "loss: 0.002694\ttrain_acc: 0.7175\telapsed_time: 795.9s\tvalid_acc: 0.6337\n",
            "Epoch: 4/20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nu2QChyYlsw4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "daec1c52-afda-4874-f6ec-e942d6fd3049"
      },
      "source": [
        "path = '/content/drive/My Drive/Colab Notebooks/IFT6285/models'\n",
        "torch.save(gru, path+filename)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type GRU. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Embedding. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BA6UsAvFlwX0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "18a3fd08-f557-45ed-b1f7-382c33560d07"
      },
      "source": [
        "gru.accuracy(valid_loader)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6761395732846652"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdLp_jk8xjxB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}