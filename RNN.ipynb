{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mk-a/NLP_Duty1/blob/master/RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3V2CQN_oGGE9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from collections import Counter\n",
        "import pickle\n",
        "import torch.nn as nn\n",
        "import time\n",
        "import gc\n",
        "import copy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ed7XBlzst9zw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "97285652-9365-4dee-8113-c04bb3082b64"
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGQX2kt0GPVq",
        "colab_type": "code",
        "outputId": "7dc8a244-f9a3-46b2-c95b-a1566b62729c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_HCjoEEGRby",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.read_pickle(\"/content/drive/My Drive/Colab Notebooks/IFT6285/train_post_preprocessed.pkl\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_AygLutL8-I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def text2seq(X, y, vocab_max, seq_len, unk_tok='UNK', padd_tok='PAD' ):\n",
        "  \"\"\" For a list of inputs X with different sequence length, associated to the labels y.\n",
        "      Builds the list of the vocab_max-2 most common words. Maps each of them to a number.\n",
        "      Replace the other words by the token unk_tok, which is mapped to the value 1.\n",
        "      Then force the input to have a sequence length of seq_len with this policy:\n",
        "        - If the sample x is short than seq_len, then adds padding at the begining.\n",
        "          The padding token is set by the variable padd_tok. And mapped to the value 0.\n",
        "        - If the sample x is longer than seq_len, then extracts (len(x)//seq_len)+1\n",
        "          sequences from x.\n",
        "  \"\"\"\n",
        "  count_words = Counter()\n",
        "  for post in X:\n",
        "    for tok in post:\n",
        "      count_words[tok] += 1\n",
        "  vocab = {w for w,_ in count_words.most_common(vocab_max-2)}.union( {unk_tok, padd_tok})\n",
        "  word2val = {w : i+2 for i, (w,_) in enumerate( count_words.most_common(vocab_max-2) )}\n",
        "  word2val[padd_tok] = 0\n",
        "  word2val[unk_tok] = 1\n",
        "\n",
        "  X2 = []\n",
        "  y2 = []\n",
        "  for i, x in enumerate(X):\n",
        "    if len(x) < seq_len:\n",
        "      tmp = x.copy()\n",
        "      for _ in range(seq_len - len(x)):\n",
        "        tmp.insert(0, padd_tok)\n",
        "      X2.append([word2val[tok] if tok in vocab else 1 for tok in tmp])\n",
        "      y2.append(y[i])\n",
        "    elif len(x) == seq_len:\n",
        "      X2.append([word2val[tok] if tok in vocab else 1 for tok in x]) \n",
        "      y2.append(y[i])\n",
        "    else :\n",
        "      for j in range(len(x)//seq_len):\n",
        "        X2.append([word2val[tok] if tok in vocab else 1 for tok in  x[j*seq_len:(j+1)*seq_len]])\n",
        "        y2.append(y[i])\n",
        "      X2.append([word2val[tok] if tok in vocab else 1 for tok in  x[-seq_len:]])\n",
        "      y2.append(y[i])\n",
        "  return word2val, X2, y2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYTcRLRASKAT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7669daa1-909f-4213-d675-4a2c2fdc66ed"
      },
      "source": [
        "vocab_max = 284467\n",
        "word2val, X, y = text2seq(data.text.values, data.label.values, vocab_max, 200) \n",
        "del data\n",
        "gc.collect()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4pntjZMzWRo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('/content/drive/My Drive/Colab Notebooks/IFT6285/word2val_{}.pkl'.format(vocab_max), 'wb') as handle:\n",
        "    pickle.dump(word2val, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "with open('/content/drive/My Drive/Colab Notebooks/IFT6285/X_v{}_s200.pkl'.format(vocab_max), 'wb') as handle:\n",
        "    pickle.dump(X, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "with open('/content/drive/My Drive/Colab Notebooks/IFT6285/y_s200.pkl', 'wb') as handle:\n",
        "    pickle.dump(y, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZ7WikSzyS21",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# with open('/content/drive/My Drive/Colab Notebooks/IFT6285/word2val_80k.pkl', 'rb') as handle:\n",
        "#     word2val = pickle.load(handle)\n",
        "# with open('/content/drive/My Drive/Colab Notebooks/IFT6285/X_v80k_s200.pkl', 'rb') as handle:\n",
        "#     X = pickle.load(handle)\n",
        "# with open('/content/drive/My Drive/Colab Notebooks/IFT6285/y_s200.pkl', 'rb') as handle:\n",
        "#     y = pickle.load(handle)\n",
        "# vocab_max = 80000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KcKdWuAV8_sU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def downsample(df, colum_name):\n",
        "    size_min = float('inf')\n",
        "    list_df = []\n",
        "    labels = df[colum_name].unique()\n",
        "    for label in labels:\n",
        "        size = len(df.loc[df[colum_name] == label])\n",
        "        if size < size_min:\n",
        "            size_min = size\n",
        "    for label in labels:\n",
        "        list_df.append(df.loc[df[colum_name] == label].sample(size_min))\n",
        "    return pd.concat(list_df).sample(frac=1).reset_index(drop=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXRqd33B9txq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4bd8d53b-9572-4bb4-b956-08931901bc1d"
      },
      "source": [
        "# df = downsample(pd.DataFrame({'X':X, 'y':y}), 'y')\n",
        "# X2 = list(df.X.values)\n",
        "# y2 = list(df.y.values)\n",
        "# del df\n",
        "# gc.collect()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "68"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xm9-8xkUfRZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.33, random_state=42)\n",
        "# X_train, X_valid, y_train, y_valid = train_test_split(X2, y2, test_size=0.33, random_state=42)\n",
        "X_valid, X_test, y_valid, y_test = train_test_split(X_valid, y_valid, test_size=0.5, random_state=42)\n",
        "X_train = torch.tensor(X_train)\n",
        "X_valid = torch.tensor(X_valid)\n",
        "X_test = torch.tensor(X_test)\n",
        "y_train = torch.tensor(y_train)\n",
        "y_valid = torch.tensor(y_valid)\n",
        "y_test = torch.tensor(y_test)\n",
        "train_data = torch.utils.data.TensorDataset(X_train, y_train)\n",
        "valid_data = torch.utils.data.TensorDataset(X_valid, y_valid)\n",
        "test_data = torch.utils.data.TensorDataset(X_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrCqo3A_sxSE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 256\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
        "valid_loader = torch.utils.data.DataLoader(valid_data, shuffle=True, batch_size=batch_size)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, shuffle=True, batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsrCqUY4tDX8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self,\n",
        "                 emb_size,\n",
        "                 hidden_size,\n",
        "                 vocab_size,\n",
        "                 num_layers,\n",
        "                 output_size,\n",
        "                 nonlinearity = 'relu',\n",
        "                 bias = True,\n",
        "                 dropout = 0,\n",
        "                 bidirectional = True\n",
        "                ):\n",
        "        super(RNN, self).__init__()\n",
        "        #hyper-parameters\n",
        "        self.emb_size      = emb_size\n",
        "        self.hidden_size   = hidden_size\n",
        "        self.vocab_size    = vocab_size\n",
        "        self.num_layers    = num_layers\n",
        "        self.output_size   = output_size\n",
        "        self.nonlinearity  = nonlinearity\n",
        "        self.bias          = bias\n",
        "        self.dropout       = dropout\n",
        "        self.bidirectional = bidirectional\n",
        "        #layers\n",
        "        self.embedding = nn.Embedding(vocab_size, emb_size).to(device)\n",
        "        self.rnn = nn.GRU(input_size = emb_size,\n",
        "                          hidden_size = hidden_size,\n",
        "                          num_layers = num_layers,\n",
        "                          bias = bias,\n",
        "                          dropout = dropout,\n",
        "                          bidirectional = bidirectional\n",
        "                         ).to(device)\n",
        "        self.linear = nn.Linear((bidirectional+1) *hidden_size, output_size).to(device)\n",
        "        \n",
        "    def forward(self, X):\n",
        "        out = self.embedding(X.t())\n",
        "        out, _ = self.rnn(out)\n",
        "        return self.linear(out[-1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L68pwNlN3f5x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_accuracy(model, data_loader):\n",
        "  correct = 0\n",
        "  for i, (X_batch, y_batch) in enumerate(data_loader):\n",
        "    torch.cuda.empty_cache()\n",
        "    X_batch = X_batch.to(device)\n",
        "    y_batch = y_batch.to(device)\n",
        "    out = model.forward(X_batch.to(device))\n",
        "    correct += (torch.max(out, 1)[1] == y_batch).float().sum()\n",
        "  return((100*correct/len(test_loader.dataset)).item())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KiPdwyIU2Yn6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def run_epoch(n_epochs, model, criterion, optimizer, train_loader, valid_loader):\n",
        "  start_time = time.time()\n",
        "  last_time = time.time()\n",
        "  prev_valid_acc = 0\n",
        "  prev_state_dict = None\n",
        "  for epoch in range(1, n_epochs+1):\n",
        "      print(\"Epoch: {}/{}\".format(epoch, n_epochs))\n",
        "      running_loss = 0\n",
        "      correct = 0\n",
        "      for i, (X_batch, y_batch) in enumerate(train_loader):\n",
        "          torch.cuda.empty_cache()\n",
        "          X_batch = X_batch.to(device)\n",
        "          y_batch = y_batch.to(device)\n",
        "          optimizer.zero_grad()\n",
        "          out = model.forward(X_batch.to(device))\n",
        "          loss = criterion(out, y_batch)\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          running_loss += loss.item()\n",
        "          correct += (torch.max(out, 1)[1] == y_batch).float().sum()\n",
        "          if time.time() - last_time > 30:\n",
        "              print(\"Samples:{}/{}\\tloss: {:.4f}\\tacc: {:2.3f}\\telapsed_time: {:.1f}s\"\\\n",
        "                    .format( (i+1)*batch_size, len(train_loader.dataset),\\\n",
        "                            running_loss/((i+1)*batch_size), 100*correct/((i+1)*batch_size), time.time()-start_time), end='\\r')\n",
        "              last_time = time.time()\n",
        "      valid_acc = compute_accuracy(model,valid_loader)\n",
        "      print(\"loss: {:.6f}\\tacc: {:2.3f}\\telapsed_time: {:.1f}s\\tvalid_acc: {:2.3f}\".format(\n",
        "          running_loss/((i+1)*batch_size), 100*correct/((i+1)*batch_size), time.time()-start_time, valid_acc))\n",
        "      if prev_valid_acc > valid_acc:\n",
        "        print(\"Stopping criteria met. Returning the model state of the previous epoch.\")\n",
        "        model.load_state_dict(prev_state_dict)\n",
        "        return\n",
        "      prev_valid_acc  = valid_acc\n",
        "      prev_state_dict = copy.deepcopy(model.state_dict())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzhZxpjVtKT0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = 'GRU'\n",
        "emb_size = 64\n",
        "hidden_size = 64\n",
        "num_layers = 6\n",
        "output_size = 3\n",
        "bidirectional=True\n",
        "filename = '{}{}_emb{}_hid{}_lay{}_vocab{}.pt'.format('bi' if bidirectional else '', model, emb_size, hidden_size, num_layers, vocab_max )\n",
        "\n",
        "\n",
        "rnn = RNN(emb_size = emb_size, hidden_size = hidden_size, vocab_size = vocab_max,\n",
        "          num_layers = num_layers, output_size = output_size, bidirectional=bidirectional)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPXpnIxVtYYw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(rnn.parameters(), weight_decay=10e-5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "91f79ffd-70d9-4b32-87de-7fa66b372063",
        "id": "7f_nGpMckgq9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "run_epoch(n_epochs=20, model=rnn, criterion=criterion, optimizer=optimizer, train_loader=train_loader, valid_loader=valid_loader)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1/20\n",
            "loss: 0.003339\tacc: 60.185\telapsed_time: 509.7s\tvalid_acc: 63.449\n",
            "Epoch: 2/20\n",
            "loss: 0.002988\tacc: 65.017\telapsed_time: 1015.8s\tvalid_acc: 66.054\n",
            "Epoch: 3/20\n",
            "loss: 0.002789\tacc: 67.718\telapsed_time: 1521.1s\tvalid_acc: 69.156\n",
            "Epoch: 4/20\n",
            "loss: 0.002627\tacc: 69.896\telapsed_time: 2025.7s\tvalid_acc: 70.402\n",
            "Epoch: 5/20\n",
            "loss: 0.002525\tacc: 71.327\telapsed_time: 2536.7s\tvalid_acc: 70.956\n",
            "Epoch: 6/20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0Vq4s-cwkJB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "compute_accuracy(rnn, valid_loader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxBisOme9-3n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "15114fca-ac86-4c10-f3a5-5a5e40f28a44"
      },
      "source": [
        "path = '/content/drive/My Drive/Colab Notebooks/IFT6285/'\n",
        "torch.save(rnn, path+filename)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type RNN. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Embedding. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type GRU. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vP3iJry6OVPd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}