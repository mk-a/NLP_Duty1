{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mk-a/NLP_Duty1/blob/master/RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3V2CQN_oGGE9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from collections import Counter\n",
        "import pickle\n",
        "import torch.nn as nn\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ed7XBlzst9zw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "97fc8abc-5c9d-47b4-9bc7-a32144c66f44"
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGQX2kt0GPVq",
        "colab_type": "code",
        "outputId": "c45b3073-40f1-41f0-e5a3-92dd3c93bb3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_HCjoEEGRby",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.read_pickle(\"/content/drive/My Drive/Colab Notebooks/IFT6285/train_post_preprocessed.pkl\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBrAyMb-G4Lu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = np.array([len(post) for post in data.text.values if len(post)<1000 ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_AygLutL8-I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def text2seq(X, y, vocab_max, seq_len, unk_tok='UNK', padd_tok='PAD' ):\n",
        "  \"\"\" For a list of inputs X with different sequence length, associated to the labels y.\n",
        "      Builds the list of the vocab_max-2 most common words. Maps each of them to a number.\n",
        "      Replace the other words by the token unk_tok, which is mapped to the value 1.\n",
        "      Then force the input to have a sequence length of seq_len with this policy:\n",
        "        - If the sample x is short than seq_len, then adds padding at the begining.\n",
        "          The padding token is set by the variable padd_tok. And mapped to the value 0.\n",
        "        - If the sample x is longer than seq_len, then extracts (len(x)//seq_len)+1\n",
        "          sequences from x.\n",
        "  \"\"\"\n",
        "  count_words = Counter()\n",
        "  for post in X:\n",
        "    for tok in post:\n",
        "      count_words[tok] += 1\n",
        "  vocab = {w for w,_ in count_words.most_common(vocab_max-2)}.union( {unk_tok, padd_tok})\n",
        "  word2val = {w : i+2 for i, (w,_) in enumerate( count_words.most_common(vocab_max-2) )}\n",
        "  word2val[padd_tok] = 0\n",
        "  word2val[unk_tok] = 1\n",
        "\n",
        "  X2 = []\n",
        "  y2 = []\n",
        "  for i, x in enumerate(X):\n",
        "    if len(x) < seq_len:\n",
        "      tmp = x.copy()\n",
        "      for _ in range(seq_len - len(x)):\n",
        "        tmp.insert(0, padd_tok)\n",
        "      X2.append([word2val[tok] if tok in vocab else 1 for tok in tmp])\n",
        "      y2.append(y[i])\n",
        "    elif len(x) == seq_len:\n",
        "      X2.append([word2val[tok] if tok in vocab else 1 for tok in x]) \n",
        "      y2.append(y[i])\n",
        "    else :\n",
        "      for j in range(len(x)//seq_len):\n",
        "        X2.append([word2val[tok] if tok in vocab else 1 for tok in  x[j*seq_len:(j+1)*seq_len]])\n",
        "        y2.append(y[i])\n",
        "      X2.append([word2val[tok] if tok in vocab else 1 for tok in  x[-seq_len:]])\n",
        "      y2.append(y[i])\n",
        "  return word2val, X2, y2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYTcRLRASKAT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_max = 80000\n",
        "word2val, X, y = text2seq(data.text.values, data.label.values, vocab_max,  200)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4pntjZMzWRo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('/content/drive/My Drive/Colab Notebooks/IFT6285/word2val_80k.pkl', 'wb') as handle:\n",
        "    pickle.dump(word2val, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "with open('/content/drive/My Drive/Colab Notebooks/IFT6285/X_v80k_s200.pkl', 'wb') as handle:\n",
        "    pickle.dump(X, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "with open('/content/drive/My Drive/Colab Notebooks/IFT6285/y_s200.pkl', 'wb') as handle:\n",
        "    pickle.dump(y, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZ7WikSzyS21",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('/content/drive/My Drive/Colab Notebooks/IFT6285/word2val_80k.pkl', 'rb') as handle:\n",
        "    word2val = pickle.load(handle)\n",
        "with open('/content/drive/My Drive/Colab Notebooks/IFT6285/X_v80k_s200.pkl', 'rb') as handle:\n",
        "    X = pickle.load(handle)\n",
        "with open('/content/drive/My Drive/Colab Notebooks/IFT6285/y_s200.pkl', 'rb') as handle:\n",
        "    y = pickle.load(handle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KcKdWuAV8_sU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def downsample(df, colum_name):\n",
        "    size_min = float('inf')\n",
        "    list_df = []\n",
        "    labels = df[colum_name].unique()\n",
        "    for label in labels:\n",
        "        size = len(df.loc[df[colum_name] == label])\n",
        "        if size < size_min:\n",
        "            size_min = size\n",
        "    for label in labels:\n",
        "        list_df.append(df.loc[df[colum_name] == label].sample(size_min))\n",
        "    return pd.concat(list_df).sample(frac=1).reset_index(drop=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXRqd33B9txq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = downsample(pd.DataFrame({'X':X, 'y':y}), 'y')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2efkZmpP97JI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X2 = list(df.X.values)\n",
        "y2 = list(df.y.values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xm9-8xkUfRZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_valid, y_train, y_valid = train_test_split(X2, y2, test_size=0.33, random_state=42)\n",
        "X_valid, X_test, y_valid, y_test = train_test_split(X_valid, y_valid, test_size=0.5, random_state=42)\n",
        "X_train = torch.tensor(X_train)\n",
        "X_valid = torch.tensor(X_valid)\n",
        "X_test = torch.tensor(X_test)\n",
        "y_train = torch.tensor(y_train)\n",
        "y_valid = torch.tensor(y_valid)\n",
        "y_test = torch.tensor(y_test)\n",
        "train_data = torch.utils.data.TensorDataset(X_train, y_train)\n",
        "valid_data = torch.utils.data.TensorDataset(X_valid, y_valid)\n",
        "test_data = torch.utils.data.TensorDataset(X_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrCqo3A_sxSE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 128\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
        "valid_loader = torch.utils.data.DataLoader(valid_data, shuffle=True, batch_size=batch_size)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, shuffle=True, batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsrCqUY4tDX8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self,\n",
        "                 emb_size,\n",
        "                 hidden_size,\n",
        "                 vocab_size,\n",
        "                 num_layers,\n",
        "                 output_size,\n",
        "                 nonlinearity = 'relu',\n",
        "                 bias = True,\n",
        "                 dropout = 0,\n",
        "                 bidirectional = True\n",
        "                ):\n",
        "        super(RNN, self).__init__()\n",
        "        #hyper-parameters\n",
        "        self.emb_size      = emb_size\n",
        "        self.hidden_size   = hidden_size\n",
        "        self.vocab_size    = vocab_size\n",
        "        self.num_layers    = num_layers\n",
        "        self.output_size   = output_size\n",
        "        self.nonlinearity  = nonlinearity\n",
        "        self.bias          = bias\n",
        "        self.dropout       = dropout\n",
        "        self.bidirectional = bidirectional\n",
        "        #layers\n",
        "        self.embedding = nn.Embedding(vocab_size, emb_size).to(device)\n",
        "        self.rnn = nn.RNN(input_size = emb_size,\n",
        "                          hidden_size = hidden_size,\n",
        "                          num_layers = num_layers,\n",
        "                          bias = bias,\n",
        "                          dropout = dropout,\n",
        "                          bidirectional = bidirectional\n",
        "                         ).to(device)\n",
        "        self.linear = nn.Linear((bidirectional+1) *hidden_size, output_size).to(device)\n",
        "        \n",
        "    def forward(self, X):\n",
        "        out = self.embedding(X.t())\n",
        "        out, _ = self.rnn(out)\n",
        "        return self.linear(out[-1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L68pwNlN3f5x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_accuracy(model, data_loader):\n",
        "  correct = 0\n",
        "  for i, (X_batch, y_batch) in enumerate(data_loader):\n",
        "    torch.cuda.empty_cache()\n",
        "    X_batch = X_batch.to(device)\n",
        "    y_batch = y_batch.to(device)\n",
        "    out = model.forward(X_batch.to(device))\n",
        "    correct += (torch.max(out, 1)[1] == y_batch).float().sum()\n",
        "  return((100*correct/len(test_loader.dataset)).item())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KiPdwyIU2Yn6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def run_epoch(n_epochs, model, criterion, optimizer, train_loader, valid_loader=None):\n",
        "  start_time = time.time()\n",
        "  last_time = time.time()\n",
        "  for epoch in range(1, n_epochs+1):\n",
        "      print(\"Epoch: {}/{}\".format(epoch, n_epochs))\n",
        "      running_loss = 0\n",
        "      correct = 0\n",
        "      for i, (X_batch, y_batch) in enumerate(train_loader):\n",
        "          torch.cuda.empty_cache()\n",
        "          X_batch = X_batch.to(device)\n",
        "          y_batch = y_batch.to(device)\n",
        "          optimizer.zero_grad()\n",
        "          out = model.forward(X_batch.to(device))\n",
        "          loss = criterion(out, y_batch)\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          running_loss += loss.item()\n",
        "          correct += (torch.max(out, 1)[1] == y_batch).float().sum()\n",
        "          if time.time() - last_time > 0.5:\n",
        "              print(\"Samples:{}/{}\\tloss: {:.4f}\\tacc: {:2.3f}\\telapsed_time: {:.1f}s\"\\\n",
        "                    .format( (i+1)*batch_size, len(train_loader.dataset),\\\n",
        "                            running_loss/((i+1)*batch_size), 100*correct/((i+1)*batch_size), time.time()-start_time), end='\\r')\n",
        "              last_time = time.time()\n",
        "      if valid_loader:\n",
        "        print(\"loss: {:.6f}\\tacc: {:2.3f}\\telapsed_time: {:.1f}s\\tvalid_acc: {:2.3f}\".format(\n",
        "                running_loss/((i+1)*batch_size), 100*correct/((i+1)*batch_size), time.time()-start_time,\n",
        "                compute_accuracy(model,valid_loader)\n",
        "        ))\n",
        "      else:\n",
        "        print(\"loss: {:.6f}\\tacc: {:2.3f}\\telapsed_time: {:.1f}s\".format(\n",
        "                running_loss/((i+1)*batch_size), 100*correct/((i+1)*batch_size), time.time()-start_time,\n",
        "        ))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzhZxpjVtKT0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rnn = RNN( emb_size = 256,\n",
        "         hidden_size = 512,\n",
        "         vocab_size = vocab_max,\n",
        "         num_layers = 2,\n",
        "         output_size = 3,\n",
        "         bidirectional=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPXpnIxVtYYw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(rnn.parameters())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfic802vtitq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "188c4507-d515-46ca-c0f7-1a42dcaa7035"
      },
      "source": [
        "run_epoch(n_epochs=10, model=rnn, criterion=criterion, optimizer=optimizer, train_loader=test_loader, valid_loader=valid_loader)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1/10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPv2qTS5_tzf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}