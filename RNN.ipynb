{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mk-a/NLP_Duty1/blob/master/RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSjIcQNZxob5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from collections import Counter\n",
        "import pickle\n",
        "import torch.nn as nn\n",
        "import time\n",
        "import gc\n",
        "import copy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vQ31UX4xw5p",
        "colab_type": "code",
        "outputId": "d3c91c50-41f0-4aef-a8c3-bf8819862bb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JRJmFEHxyIM",
        "colab_type": "code",
        "outputId": "db69172f-d025-487f-c247-de6692bd98a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKM52fQMx0HB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data = pd.read_pickle(\"/content/drive/My Drive/Colab Notebooks/IFT6285/test_preprocessed.pkl\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4izxu0lRyB-u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def text2seq(X, y, vocab_max, seq_len, unk_tok='UNK', padd_tok='PAD' ):\n",
        "  \"\"\" For a list of inputs X with different sequence length, associated to the labels y.\n",
        "      Builds the list of the vocab_max-2 most common words. Maps each of them to a number.\n",
        "      Replace the other words by the token unk_tok, which is mapped to the value 1.\n",
        "      Then force the input to have a sequence length of seq_len with this policy:\n",
        "        - If the sample x is short than seq_len, then adds padding at the begining.\n",
        "          The padding token is set by the variable padd_tok. And mapped to the value 0.\n",
        "        - If the sample x is longer than seq_len, then extracts (len(x)//seq_len)+1\n",
        "          sequences from x.\n",
        "  \"\"\"\n",
        "  count_words = Counter()\n",
        "  for post in X:\n",
        "    for tok in post:\n",
        "      count_words[tok] += 1\n",
        "  vocab = {w for w,_ in count_words.most_common(vocab_max-2)}.union( {unk_tok, padd_tok})\n",
        "  word2val = {w : i+2 for i, (w,_) in enumerate( count_words.most_common(vocab_max-2) )}\n",
        "  word2val[padd_tok] = 0\n",
        "  word2val[unk_tok] = 1\n",
        "\n",
        "  X2 = []\n",
        "  y2 = []\n",
        "  for i, x in enumerate(X):\n",
        "    if len(x) < seq_len:\n",
        "      tmp = x.copy()\n",
        "      for _ in range(seq_len - len(x)):\n",
        "        tmp.insert(0, padd_tok)\n",
        "      X2.append([word2val[tok] if tok in vocab else 1 for tok in tmp])\n",
        "      y2.append(y[i])\n",
        "    elif len(x) == seq_len:\n",
        "      X2.append([word2val[tok] if tok in vocab else 1 for tok in x]) \n",
        "      y2.append(y[i])\n",
        "    else :\n",
        "      for j in range(len(x)//seq_len):\n",
        "        X2.append([word2val[tok] if tok in vocab else 1 for tok in  x[j*seq_len:(j+1)*seq_len]])\n",
        "        y2.append(y[i])\n",
        "      X2.append([word2val[tok] if tok in vocab else 1 for tok in  x[-seq_len:]])\n",
        "      y2.append(y[i])\n",
        "  return word2val, X2, y2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wOd_UWgyEk3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_max = 284467\n",
        "word2val, X, y = text2seq(data.text.values, data.label.values, vocab_max, 200) \n",
        "# del data\n",
        "# gc.collect()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTh-vz6GyJj8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('/content/drive/My Drive/Colab Notebooks/IFT6285/v2/word2val_{}.pkl'.format(vocab_max), 'wb') as handle:\n",
        "    pickle.dump(word2val, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "with open('/content/drive/My Drive/Colab Notebooks/IFT6285/v2/X_v{}_s200.pkl'.format(vocab_max), 'wb') as handle:\n",
        "    pickle.dump(X, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "with open('/content/drive/My Drive/Colab Notebooks/IFT6285/v2/y_s200.pkl', 'wb') as handle:\n",
        "    pickle.dump(y, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6j1yuP4oyknm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.33, random_state=42)\n",
        "# # X_train, X_valid, y_train, y_valid = train_test_split(X2, y2, test_size=0.33, random_state=42)\n",
        "# X_valid, X_test, y_valid, y_test = train_test_split(X_valid, y_valid, test_size=0.5, random_state=42)\n",
        "X_train = torch.tensor(X_train)\n",
        "X_valid = torch.tensor(X_valid)\n",
        "X_test = torch.tensor(X_test)\n",
        "y_train = torch.tensor(y_train)\n",
        "y_valid = torch.tensor(y_valid)\n",
        "y_test = torch.tensor(y_test)\n",
        "train_data = torch.utils.data.TensorDataset(X_train, y_train)\n",
        "valid_data = torch.utils.data.TensorDataset(X_valid, y_valid)\n",
        "test_data = torch.utils.data.TensorDataset(X_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYVFMa62ynr7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 256\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
        "valid_loader = torch.utils.data.DataLoader(valid_data, shuffle=True, batch_size=batch_size)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, shuffle=True, batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DO74EuZ1ypXP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self,\n",
        "                 emb_size,\n",
        "                 hidden_size,\n",
        "                 vocab_size,\n",
        "                 num_layers,\n",
        "                 output_size,\n",
        "                 nonlinearity = 'relu',\n",
        "                 bias = True,\n",
        "                 dropout = 0,\n",
        "                 bidirectional = True\n",
        "                ):\n",
        "        super(RNN, self).__init__()\n",
        "        #hyper-parameters\n",
        "        self.emb_size      = emb_size\n",
        "        self.hidden_size   = hidden_size\n",
        "        self.vocab_size    = vocab_size\n",
        "        self.num_layers    = num_layers\n",
        "        self.output_size   = output_size\n",
        "        self.nonlinearity  = nonlinearity\n",
        "        self.bias          = bias\n",
        "        self.dropout       = dropout\n",
        "        self.bidirectional = bidirectional\n",
        "        #layers\n",
        "        self.embedding = nn.Embedding(vocab_size, emb_size).to(device)\n",
        "        self.rnn = nn.GRU(input_size = emb_size,\n",
        "                          hidden_size = hidden_size,\n",
        "                          num_layers = num_layers,\n",
        "                          bias = bias,\n",
        "                          dropout = dropout,\n",
        "                          bidirectional = bidirectional\n",
        "                         ).to(device)\n",
        "        self.linear = nn.Linear((bidirectional+1) *hidden_size, output_size).to(device)\n",
        "        \n",
        "    def forward(self, X):\n",
        "        out = self.embedding(X.t())\n",
        "        out, _ = self.rnn(out)\n",
        "        return self.linear(out[-1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7TqCs2VyrAz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_accuracy(model, data_loader):\n",
        "  correct = 0\n",
        "  for i, (X_batch, y_batch) in enumerate(data_loader):\n",
        "    torch.cuda.empty_cache()\n",
        "    X_batch = X_batch.to(device)\n",
        "    y_batch = y_batch.to(device)\n",
        "    out = model.forward(X_batch.to(device))\n",
        "    correct += (torch.max(out, 1)[1] == y_batch).float().sum()\n",
        "  return((100*correct/len(test_loader.dataset)).item())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMwwY9F7ys1o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def run_epoch(n_epochs, model, criterion, optimizer, train_loader, valid_loader, stop_crit=True):\n",
        "  start_time = time.time()\n",
        "  last_time = time.time()\n",
        "  prev_valid_acc = 0\n",
        "  prev_state_dict = None\n",
        "  epochs_since_best_acc = 0\n",
        "  for epoch in range(1, n_epochs+1):\n",
        "      print(\"Epoch: {}/{}\".format(epoch, n_epochs))\n",
        "      running_loss = 0\n",
        "      correct = 0\n",
        "      for i, (X_batch, y_batch) in enumerate(train_loader):\n",
        "          torch.cuda.empty_cache()\n",
        "          X_batch = X_batch.to(device)\n",
        "          y_batch = y_batch.to(device)\n",
        "          optimizer.zero_grad()\n",
        "          out = model.forward(X_batch.to(device))\n",
        "          loss = criterion(out, y_batch)\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          running_loss += loss.item()\n",
        "          correct += (torch.max(out, 1)[1] == y_batch).float().sum()\n",
        "          if time.time() - last_time > 30:\n",
        "              print(\"Samples:{}/{}\\tloss: {:.4f}\\tacc: {:2.3f}\\telapsed_time: {:.1f}s\"\\\n",
        "                    .format( (i+1)*batch_size, len(train_loader.dataset),\\\n",
        "                            running_loss/((i+1)*batch_size), 100*correct/((i+1)*batch_size), time.time()-start_time), end='\\r')\n",
        "              last_time = time.time()\n",
        "      valid_acc = compute_accuracy(model,valid_loader)\n",
        "      print(\"loss: {:.6f}\\tacc: {:2.3f}\\telapsed_time: {:.1f}s\\tvalid_acc: {:2.3f}\".format(\n",
        "          running_loss/((i+1)*batch_size), 100*correct/((i+1)*batch_size), time.time()-start_time, valid_acc))\n",
        "      if stop_crit and prev_valid_acc > valid_acc:\n",
        "        print(\"Stopping criteria met. Returning the model state of the previous epoch.\")\n",
        "        model.load_state_dict(prev_state_dict)\n",
        "        return\n",
        "      prev_valid_acc  = valid_acc\n",
        "      prev_state_dict = copy.deepcopy(model.state_dict())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zR2Odn1kyvpd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = 'GRU'\n",
        "emb_size = 64\n",
        "hidden_size = 64\n",
        "num_layers = 6\n",
        "output_size = 3\n",
        "bidirectional=True\n",
        "filename = '{}{}_emb{}_hid{}_lay{}_vocab{}.pt'.format('bi' if bidirectional else '', model, emb_size, hidden_size, num_layers, vocab_max )\n",
        "\n",
        "\n",
        "rnn = RNN(emb_size = emb_size, hidden_size = hidden_size, vocab_size = vocab_max,\n",
        "          num_layers = num_layers, output_size = output_size, bidirectional=bidirectional)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7NzXV3bfy24C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(rnn.parameters(), weight_decay=10e-5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwj3dCXby5aJ",
        "colab_type": "code",
        "outputId": "45db4dd1-b948-4104-f307-43d5d40508fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "run_epoch(n_epochs=20, model=rnn, criterion=criterion, optimizer=optimizer, train_loader=train_loader, valid_loader=valid_loader, stop_crit=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1/20\n",
            "loss: 0.003351\tacc: 60.023\telapsed_time: 482.9s\tvalid_acc: 63.439\n",
            "Epoch: 2/20\n",
            "loss: 0.002997\tacc: 64.794\telapsed_time: 971.1s\tvalid_acc: 66.180\n",
            "Epoch: 3/20\n",
            "loss: 0.002811\tacc: 67.434\telapsed_time: 1456.2s\tvalid_acc: 68.509\n",
            "Epoch: 4/20\n",
            "loss: 0.002681\tacc: 69.261\telapsed_time: 1946.5s\tvalid_acc: 68.261\n",
            "Stopping criteria met. Returning the model state of the previous epoch.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wK6dOnzt_chw",
        "colab_type": "code",
        "outputId": "b0808f5c-d0be-427c-ba2d-f8cb6a1fb8b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "path = '/content/drive/My Drive/Colab Notebooks/IFT6285/v2/'\n",
        "torch.save(rnn, path+filename)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type RNN. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Embedding. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type GRU. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sc5nXdOk3jP_",
        "colab_type": "code",
        "outputId": "c5dc5286-5e63-4f11-b8eb-fb18c96f8fc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "run_epoch(n_epochs=3, model=rnn, criterion=criterion, optimizer=optimizer, train_loader=train_loader, valid_loader=valid_loader, stop_crit=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1/3\n",
            "loss: 0.002670\tacc: 69.401\telapsed_time: 489.4s\tvalid_acc: 69.464\n",
            "Epoch: 2/3\n",
            "loss: 0.002584\tacc: 70.524\telapsed_time: 978.9s\tvalid_acc: 70.732\n",
            "Epoch: 3/3\n",
            "loss: 0.002503\tacc: 71.675\telapsed_time: 1470.3s\tvalid_acc: 71.374\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Twmg4Owx_lq8",
        "colab_type": "code",
        "outputId": "0d7ee974-4aaa-4887-9177-c53fef3eec24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "run_epoch(n_epochs=3, model=rnn, criterion=criterion, optimizer=optimizer, train_loader=train_loader, valid_loader=valid_loader, stop_crit=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1/3\n",
            "loss: 0.002422\tacc: 72.786\telapsed_time: 488.7s\tvalid_acc: 71.543\n",
            "Epoch: 2/3\n",
            "loss: 0.002344\tacc: 73.805\telapsed_time: 981.7s\tvalid_acc: 72.514\n",
            "Epoch: 3/3\n",
            "loss: 0.002271\tacc: 74.854\telapsed_time: 1470.5s\tvalid_acc: 72.601\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmXiT4qWF4t9",
        "colab_type": "code",
        "outputId": "69ba0777-2833-4e3c-de39-7b9aa0b6219f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "run_epoch(n_epochs=6, model=rnn, criterion=criterion, optimizer=optimizer, train_loader=train_loader, valid_loader=valid_loader, stop_crit=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1/6\n",
            "loss: 0.002193\tacc: 75.882\telapsed_time: 490.4s\tvalid_acc: 73.165\n",
            "Epoch: 2/6\n",
            "loss: 0.002116\tacc: 76.800\telapsed_time: 973.8s\tvalid_acc: 73.399\n",
            "Epoch: 3/6\n",
            "loss: 0.002021\tacc: 77.968\telapsed_time: 1461.2s\tvalid_acc: 73.582\n",
            "Epoch: 4/6\n",
            "loss: 0.001927\tacc: 79.165\telapsed_time: 1953.5s\tvalid_acc: 73.824\n",
            "Epoch: 5/6\n",
            "loss: 0.001836\tacc: 80.223\telapsed_time: 2440.4s\tvalid_acc: 73.947\n",
            "Epoch: 6/6\n",
            "loss: 0.001771\tacc: 80.953\telapsed_time: 2929.0s\tvalid_acc: 73.416\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QaubZ_6rM1ec",
        "colab_type": "code",
        "outputId": "71450cc8-e82d-41e3-91b9-09871f8df13f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "path = '/content/drive/My Drive/Colab Notebooks/IFT6285/v2/'\n",
        "torch.save(rnn, path+filename)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type RNN. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Embedding. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type GRU. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qC0oO3gBYT4s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}